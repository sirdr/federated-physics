{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1ccf8-9f78-4f1f-aaf0-2df025e94b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from the_well.benchmark.metrics import VRMSE\n",
    "from the_well.data import WellDataset, datasets\n",
    "from the_well.utils.download import well_download\n",
    "from the_well.benchmark import models\n",
    "from the_well.benchmark.models import UNetConvNext\n",
    "\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d5a1c-ddde-4d56-8148-187b60ad6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unetconvnext_from_local(dataset_name: str,\n",
    "                                 model_base=\"data/model-data/benchmarks\",\n",
    "                                 dataset_base=\"data/datasets\"):\n",
    "    # Locate model directory\n",
    "    all_dirs = os.listdir(model_base)\n",
    "    match = next(\n",
    "        (d for d in all_dirs if dataset_name in d and d.startswith(\"UNetConvNext\")),\n",
    "        None\n",
    "    )\n",
    "    if not match:\n",
    "        raise FileNotFoundError(f\"No local model found for dataset '{dataset_name}' in {model_base}\")\n",
    "\n",
    "    model_dir = os.path.join(model_base, match)\n",
    "    config_path = os.path.join(model_dir, \"config.json\")\n",
    "    safetensor_path = os.path.join(model_dir, \"model.safetensors\")\n",
    "\n",
    "    if not os.path.exists(config_path) or not os.path.exists(safetensor_path):\n",
    "        raise FileNotFoundError(\"Missing config.json or model.safetensors in model directory.\")\n",
    "\n",
    "    # Load config.json\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Load metadata YAML\n",
    "    yaml_path = os.path.join(dataset_base, dataset_name, f\"{dataset_name}.yaml\")\n",
    "    if not os.path.exists(yaml_path):\n",
    "        raise FileNotFoundError(f\"Missing metadata YAML: {yaml_path}\")\n",
    "\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        metadata = yaml.safe_load(f)\n",
    "\n",
    "    # Extract model parameters\n",
    "    model_kwargs = {\n",
    "        \"dim_in\": config[\"dim_in\"],\n",
    "        \"dim_out\": config[\"dim_out\"],\n",
    "        \"stages\": config.get(\"stages\", 4),\n",
    "        \"blocks_per_stage\": config.get(\"blocks_per_stage\", 1),\n",
    "        \"blocks_at_neck\": config.get(\"blocks_at_neck\", 1),\n",
    "        \"init_features\": config.get(\"init_features\", 32),\n",
    "        \"gradient_checkpointing\": config.get(\"gradient_checkpointing\", False),\n",
    "        \"n_spatial_dims\": metadata[\"n_spatial_dims\"],\n",
    "        \"spatial_resolution\": tuple(metadata[\"spatial_resolution\"]),\n",
    "    }\n",
    "\n",
    "    # Instantiate and load weights\n",
    "    model = UNetConvNext(**model_kwargs)\n",
    "    state_dict = load_file(safetensor_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    return model, model_kwargs, model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4536c-1851-45d8-8f32-3a481ae6db7a",
   "metadata": {},
   "source": [
    "Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11392f63-598a-41fa-9487-54fb41c17a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base = \"data/datasets\"\n",
    "dataset_name = \"turbulent_radiative_layer_2D\"\n",
    "model, model_kwargs, path = load_unetconvnext_from_local(dataset_name, dataset_base=dataset_base)\n",
    "\n",
    "testset = datasets.WellDataset(\n",
    "    well_base_path=\"data/datasets/\",\n",
    "    well_dataset_name=dataset_name,\n",
    "    well_split_name=\"test\",\n",
    "    n_steps_input=4,\n",
    "    n_steps_output=1,\n",
    "    use_normalization=False,\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset=testset,\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124758b-d648-4bd1-b2e2-e04bb7b115f2",
   "metadata": {},
   "source": [
    "Get training data statistics from stats.yaml file and define pre and post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc86075-f211-4763-abac-304653f226b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = os.path.join(dataset_base, dataset_name, \"stats.yaml\")\n",
    "\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    stats = yaml.safe_load(f)\n",
    "\n",
    "# Flatten into a list: [density, pressure, velocity_x, velocity_y]\n",
    "mean_vals = [\n",
    "    stats[\"mean\"][\"density\"],\n",
    "    stats[\"mean\"][\"pressure\"],\n",
    "    stats[\"mean\"][\"velocity\"][0],\n",
    "    stats[\"mean\"][\"velocity\"][1]\n",
    "]\n",
    "std_vals = [\n",
    "    stats[\"std\"][\"density\"],\n",
    "    stats[\"std\"][\"pressure\"],\n",
    "    stats[\"std\"][\"velocity\"][0],\n",
    "    stats[\"std\"][\"velocity\"][1]\n",
    "]\n",
    "\n",
    "device = \"cpu\" # change if using gpu\n",
    "\n",
    "mean_tensor = torch.tensor(mean_vals).view(1, 1, 1, 1, -1).to(device)  # shape (1,1,1,1,4)\n",
    "std_tensor = torch.tensor(std_vals).view(1, 1, 1, 1, -1).to(device)    # shape (1,1,1,1,4)\n",
    "\n",
    "def preprocess(x):\n",
    "    return (x - mean_tensor) / std_tensor\n",
    "\n",
    "def postprocess(x):\n",
    "    return std_tensor * x + mean_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f957150-19ff-4865-b3b4-e58cd06ff966",
   "metadata": {},
   "source": [
    "Register hooks for target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88e191-5006-4076-998b-0f50d07ed88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(module, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "hooks = []\n",
    "\n",
    "target_layer_names = [\"encoder.3.blocks.1.dwconv\",]  # update this list\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if name in target_layer_names:\n",
    "        hook = module.register_forward_hook(get_activation(name))\n",
    "        hooks.append(hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921b79e-80c7-4d54-bd78-7252a2e94996",
   "metadata": {},
   "source": [
    "Collect activations for real data and noise, save each batch to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11c391-545a-45d6-9616-145ddf31d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data/activations\"\n",
    "model_name = \"UNetConvNext\"\n",
    "split_name = \"test\"\n",
    "\n",
    "save_dir = f\"{base_dir}/{model_name}-{dataset_name}/{split_name}\"\n",
    "\n",
    "def save_batch(save_dir, layer_name, data, kind, batch_idx):\n",
    "    path = os.path.join(base_dir, f\"{kind}_{layer_name}_batch{batch_idx}.pt\")\n",
    "    torch.save(data.cpu(), path)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(testloader, desc=\"Streaming activations to disk\")):\n",
    "        # Real data\n",
    "        x = batch[\"input_fields\"].to(device)\n",
    "        x = preprocess(x)\n",
    "        x = rearrange(x, \"B Ti Lx Ly F -> B (Ti F) Lx Ly\")\n",
    "        _ = model(x)\n",
    "\n",
    "        for name, act in activations.items():\n",
    "            save_batch(save_dir, name, act.flatten(start_dim=1), \"real\", batch_idx)\n",
    "\n",
    "        # Noise\n",
    "        noise_x = torch.randn_like(x)\n",
    "        _ = model(noise_x)\n",
    "\n",
    "        for name, act in activations.items():\n",
    "            save_batch(save_dir, name, act.flatten(start_dim=1), \"noise\", batch_idx)\n",
    "\n",
    "        # Free up memory\n",
    "        del x, noise_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf531cd0-e458-48c8-8463-3c545bd1c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unhook after use\n",
    "for hook in hooks:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416334b-5612-42d4-a2a4-e3623b1b8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_streamed_activations(base_dir, model_name, dataset_name, split_name, kind=\"real\", layer_name=None):\n",
    "    base_dir = f\"{base_dir}/{model_name}-{dataset_name}/{split_name}\"\n",
    "    pattern = f\"{kind}_{layer_name}_batch*.pt\" if layer_name else f\"{kind}_*_batch*.pt\"\n",
    "    filepaths = sorted(glob.glob(os.path.join(base_dir, pattern)))\n",
    "\n",
    "    if not filepaths:\n",
    "        raise FileNotFoundError(f\"No matching activation files found at: {base_dir}/{pattern}\")\n",
    "\n",
    "    # Load and concatenate\n",
    "    batches = [torch.load(path) for path in filepaths]\n",
    "    return torch.cat(batches, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2be94-5752-4a60-a316-7300c38d7514",
   "metadata": {},
   "source": [
    "Load activations from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10241b7a-3d7b-4026-85e5-1bb4b298544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_activations = load_streamed_activations(\"data/activations\", model_name, dataset_name, \"test\", kind=\"real\", layer_name=\"encoder.3.blocks.1.dwconv\")\n",
    "noise_activations = load_streamed_activations(\"data/activations\", model_name, dataset_name, \"test\", kind=\"noise\", layer_name=\"encoder.3.blocks.1.dwconv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c2e3c-7187-4a46-a6e6-827d48916476",
   "metadata": {},
   "source": [
    "See if noise and real activations are linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d927272-b290-461b-868b-f1bda3fc6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume real_activations and noise_activations are torch.Tensors\n",
    "X_real = real_activations.numpy()\n",
    "X_noise = noise_activations.numpy()\n",
    "\n",
    "X = np.concatenate([X_real, X_noise], axis=0)\n",
    "y = np.concatenate([\n",
    "    np.ones(len(X_real)),   # label 1 = real\n",
    "    np.zeros(len(X_noise))  # label 0 = noise\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24e23f-38f2-4ab2-9d5d-10b7c74e2fd6",
   "metadata": {},
   "source": [
    "Visualize decision boundary in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ba25f-8092-49ab-8519-9e6539c78122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize full feature set before PCA\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "X_test_pca = PCA(n_components=2).fit_transform(X_test_scaled)\n",
    "\n",
    "# Train a new classifier in 2D just for visualization\n",
    "clf_2d = LogisticRegression(max_iter=1000)\n",
    "clf_2d.fit(X_test_pca, y_test)\n",
    "\n",
    "# Meshgrid for contour plot\n",
    "h = 0.05\n",
    "# Range of grid\n",
    "x_min, x_max = X_test_pca[:, 0].min() - 1, X_test_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_test_pca[:, 1].min() - 1, X_test_pca[:, 1].max() + 1\n",
    "\n",
    "# Cap grid resolution\n",
    "grid_points = 300  # reduce to 200â€“500 as needed\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, grid_points),\n",
    "    np.linspace(y_min, y_max, grid_points)\n",
    ")\n",
    "Z = clf_2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)\n",
    "plt.scatter(X_test_pca[y_test == 0, 0], X_test_pca[y_test == 0, 1], label='Noise', alpha=0.7)\n",
    "plt.scatter(X_test_pca[y_test == 1, 0], X_test_pca[y_test == 1, 1], label='Real', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title(\"Decision Boundary (PCA projection)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
